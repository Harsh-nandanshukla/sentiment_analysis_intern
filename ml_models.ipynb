{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set shape: (1010826, 10)\n",
      "Test set shape: (32332, 3)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load datasets\n",
    "train_df = pd.read_csv(\"train-balanced-sarcasm.csv\", low_memory=False)\n",
    "test_df = pd.read_csv(\"test-balanced.csv\", low_memory=False)\n",
    "\n",
    "# Check shape\n",
    "print(\"Train set shape:\", train_df.shape)\n",
    "print(\"Test set shape:\", test_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train columns: ['label', 'comment', 'author', 'subreddit', 'score', 'ups', 'downs', 'date', 'created_utc', 'parent_comment']\n",
      "Nulls in train:\n",
      " label              0\n",
      "comment           55\n",
      "author             0\n",
      "subreddit          0\n",
      "score              0\n",
      "ups                0\n",
      "downs              0\n",
      "date               0\n",
      "created_utc        0\n",
      "parent_comment     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Train columns:\", train_df.columns.tolist())\n",
    "print(\"Nulls in train:\\n\", train_df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>comment</th>\n",
       "      <th>author</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>score</th>\n",
       "      <th>ups</th>\n",
       "      <th>downs</th>\n",
       "      <th>date</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>parent_comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NC and NH.</td>\n",
       "      <td>Trumpbart</td>\n",
       "      <td>politics</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2016-10</td>\n",
       "      <td>2016-10-16 23:55:23</td>\n",
       "      <td>Yeah, I get that argument. At this point, I'd ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>You do know west teams play against west teams...</td>\n",
       "      <td>Shbshb906</td>\n",
       "      <td>nba</td>\n",
       "      <td>-4</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2016-11</td>\n",
       "      <td>2016-11-01 00:24:10</td>\n",
       "      <td>The blazers and Mavericks (The wests 5 and 6 s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>They were underdogs earlier today, but since G...</td>\n",
       "      <td>Creepeth</td>\n",
       "      <td>nfl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-09</td>\n",
       "      <td>2016-09-22 21:45:37</td>\n",
       "      <td>They're favored to win.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>This meme isn't funny none of the \"new york ni...</td>\n",
       "      <td>icebrotha</td>\n",
       "      <td>BlackPeopleTwitter</td>\n",
       "      <td>-8</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2016-10</td>\n",
       "      <td>2016-10-18 21:03:47</td>\n",
       "      <td>deadass don't kill my buzz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>I could use one of those tools.</td>\n",
       "      <td>cush2push</td>\n",
       "      <td>MaddenUltimateTeam</td>\n",
       "      <td>6</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2016-12</td>\n",
       "      <td>2016-12-30 17:00:13</td>\n",
       "      <td>Yep can confirm I saw the tool they use for th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010821</th>\n",
       "      <td>1</td>\n",
       "      <td>I'm sure that Iran and N. Korea have the techn...</td>\n",
       "      <td>TwarkMain</td>\n",
       "      <td>reddit.com</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2009-04</td>\n",
       "      <td>2009-04-25 00:47:52</td>\n",
       "      <td>No one is calling this an engineered pathogen,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010822</th>\n",
       "      <td>1</td>\n",
       "      <td>whatever you do, don't vote green!</td>\n",
       "      <td>BCHarvey</td>\n",
       "      <td>climate</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2009-05</td>\n",
       "      <td>2009-05-14 22:27:40</td>\n",
       "      <td>In a move typical of their recent do-nothing a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010823</th>\n",
       "      <td>1</td>\n",
       "      <td>Perhaps this is an atheist conspiracy to make ...</td>\n",
       "      <td>rebelcommander</td>\n",
       "      <td>atheism</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2009-01</td>\n",
       "      <td>2009-01-11 00:22:57</td>\n",
       "      <td>Screw the Disabled--I've got to get to Church ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010824</th>\n",
       "      <td>1</td>\n",
       "      <td>The Slavs got their own country - it is called...</td>\n",
       "      <td>catsi</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2009-01</td>\n",
       "      <td>2009-01-23 21:12:49</td>\n",
       "      <td>I've always been unsettled by that. I hear a l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010825</th>\n",
       "      <td>1</td>\n",
       "      <td>values, as in capitalism .. there is good mone...</td>\n",
       "      <td>frogking</td>\n",
       "      <td>politics</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2009-01</td>\n",
       "      <td>2009-01-24 06:20:14</td>\n",
       "      <td>Why do the people who make our laws seem unabl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1010826 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         label                                            comment  \\\n",
       "0            0                                         NC and NH.   \n",
       "1            0  You do know west teams play against west teams...   \n",
       "2            0  They were underdogs earlier today, but since G...   \n",
       "3            0  This meme isn't funny none of the \"new york ni...   \n",
       "4            0                    I could use one of those tools.   \n",
       "...        ...                                                ...   \n",
       "1010821      1  I'm sure that Iran and N. Korea have the techn...   \n",
       "1010822      1                 whatever you do, don't vote green!   \n",
       "1010823      1  Perhaps this is an atheist conspiracy to make ...   \n",
       "1010824      1  The Slavs got their own country - it is called...   \n",
       "1010825      1  values, as in capitalism .. there is good mone...   \n",
       "\n",
       "                 author           subreddit  score  ups  downs     date  \\\n",
       "0             Trumpbart            politics      2   -1     -1  2016-10   \n",
       "1             Shbshb906                 nba     -4   -1     -1  2016-11   \n",
       "2              Creepeth                 nfl      3    3      0  2016-09   \n",
       "3             icebrotha  BlackPeopleTwitter     -8   -1     -1  2016-10   \n",
       "4             cush2push  MaddenUltimateTeam      6   -1     -1  2016-12   \n",
       "...                 ...                 ...    ...  ...    ...      ...   \n",
       "1010821       TwarkMain          reddit.com      2    2      0  2009-04   \n",
       "1010822        BCHarvey             climate      1    1      0  2009-05   \n",
       "1010823  rebelcommander             atheism      1    1      0  2009-01   \n",
       "1010824           catsi           worldnews      1    1      0  2009-01   \n",
       "1010825        frogking            politics      2    2      0  2009-01   \n",
       "\n",
       "                 created_utc  \\\n",
       "0        2016-10-16 23:55:23   \n",
       "1        2016-11-01 00:24:10   \n",
       "2        2016-09-22 21:45:37   \n",
       "3        2016-10-18 21:03:47   \n",
       "4        2016-12-30 17:00:13   \n",
       "...                      ...   \n",
       "1010821  2009-04-25 00:47:52   \n",
       "1010822  2009-05-14 22:27:40   \n",
       "1010823  2009-01-11 00:22:57   \n",
       "1010824  2009-01-23 21:12:49   \n",
       "1010825  2009-01-24 06:20:14   \n",
       "\n",
       "                                            parent_comment  \n",
       "0        Yeah, I get that argument. At this point, I'd ...  \n",
       "1        The blazers and Mavericks (The wests 5 and 6 s...  \n",
       "2                                  They're favored to win.  \n",
       "3                               deadass don't kill my buzz  \n",
       "4        Yep can confirm I saw the tool they use for th...  \n",
       "...                                                    ...  \n",
       "1010821  No one is calling this an engineered pathogen,...  \n",
       "1010822  In a move typical of their recent do-nothing a...  \n",
       "1010823  Screw the Disabled--I've got to get to Church ...  \n",
       "1010824  I've always been unsettled by that. I hear a l...  \n",
       "1010825  Why do the people who make our laws seem unabl...  \n",
       "\n",
       "[1010826 rows x 10 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned train shape: (1010771, 10)\n"
     ]
    }
   ],
   "source": [
    "# Drop rows with null comments\n",
    "train_df = train_df.dropna(subset=[\"comment\"]).reset_index(drop=True)\n",
    "print(\"Cleaned train shape:\", train_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "0    505403\n",
      "1    505368\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_df['label'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def preprocess(text):\n",
    "    text = str(text).lower()                                      # Lowercase\n",
    "    text = re.sub(r'<.*?>', '', text)                             # Remove HTML tags\n",
    "    text = re.sub(r\"http\\S+|www\\S+\", '', text)                    # Remove URLs\n",
    "    text = re.sub(r\"\\d+\", '', text)                               # Remove numbers\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))  # Remove punctuation\n",
    "    tokens = word_tokenize(text)                                  # Tokenize\n",
    "    tokens = [stemmer.stem(w) for w in tokens if w not in stop_words and len(w) > 1]  # Remove stopwords and stem\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Apply it to the dataset\n",
    "train_df['clean_comment'] = train_df['comment'].apply(preprocess)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Top 20 misspelled words and their counts:\n",
      "\n",
      "dont: 42482\n",
      "peopl: 34981\n",
      "im: 32715\n",
      "realli: 18879\n",
      "didnt: 14846\n",
      "doesnt: 13293\n",
      "tri: 12393\n",
      "isnt: 11580\n",
      "someth: 10518\n",
      "probabl: 10359\n",
      "someon: 10141\n",
      "pretti: 10063\n",
      "everyon: 9730\n",
      "theyr: 9558\n",
      "everi: 9396\n",
      "mayb: 9278\n",
      "alway: 8774\n",
      "lol: 8200\n",
      "anyth: 7597\n",
      "clearli: 7321\n",
      "\n",
      " Sample rows with misspellings:\n",
      "                                              comment  \\\n",
      "0                                          NC and NH.   \n",
      "2   They were underdogs earlier today, but since G...   \n",
      "3   This meme isn't funny none of the \"new york ni...   \n",
      "5   I don't pay attention to her, but as long as s...   \n",
      "6       Trick or treating in general is just weird...   \n",
      "7                     Blade Mastery+Masamune or GTFO!   \n",
      "8   You don't have to, you have a good build, buy ...   \n",
      "9                   I would love to see him at lolla.   \n",
      "10  I think a significant amount would be against ...   \n",
      "14  Ayy bb wassup, it makes a bit more sense in co...   \n",
      "\n",
      "                                        clean_comment  \\\n",
      "0                                               nc nh   \n",
      "2   underdog earlier today sinc gronk announc afte...   \n",
      "3             meme isnt funni none new york nigga one   \n",
      "5   dont pay attent long she legal wouldnt kick be...   \n",
      "6                             trick treat gener weird   \n",
      "7                           blade masterymasamun gtfo   \n",
      "8                       dont good build buy game save   \n",
      "9                                would love see lolla   \n",
      "10  think signific amount would spend tax dollar p...   \n",
      "14                ayi bb wassup make bit sens context   \n",
      "\n",
      "           misspelled_words  misspelled_count  \n",
      "0                  [nc, nh]                 2  \n",
      "2    [announc, gronk, sinc]                 3  \n",
      "3      [isnt, funni, nigga]                 3  \n",
      "5   [wouldnt, dont, attent]                 3  \n",
      "6                   [gener]                 1  \n",
      "7    [masterymasamun, gtfo]                 2  \n",
      "8                    [dont]                 1  \n",
      "9                   [lolla]                 1  \n",
      "10        [peopl, signific]                 2  \n",
      "14        [ayi, bb, wassup]                 3  \n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from spellchecker import SpellChecker\n",
    "\n",
    "spell = SpellChecker()\n",
    "\n",
    "def find_misspelled_words(text):\n",
    "    words = text.split()\n",
    "    misspelled = spell.unknown(words)\n",
    "    return list(misspelled)\n",
    "\n",
    "# Step 1: Add misspelled words column\n",
    "train_df['misspelled_words'] = train_df['clean_comment'].apply(find_misspelled_words)\n",
    "\n",
    "# Step 2: Count of misspelled words per row\n",
    "train_df['misspelled_count'] = train_df['misspelled_words'].apply(len)\n",
    "\n",
    "# Step 3: Filter rows where misspelled words exist\n",
    "misspelled_rows = train_df[train_df['misspelled_count'] > 0]\n",
    "\n",
    "# Step 4: Combine all misspelled words into one list and count frequency\n",
    "all_misspelled = [word for sublist in misspelled_rows['misspelled_words'] for word in sublist]\n",
    "misspelled_freq = Counter(all_misspelled)\n",
    "\n",
    "# Step 5: Display top 20 most frequent misspellings\n",
    "print(\"🔍 Top 20 misspelled words and their counts:\\n\")\n",
    "for word, count in misspelled_freq.most_common(20):\n",
    "    print(f\"{word}: {count}\")\n",
    "\n",
    "# Optional: Preview rows with misspelled words\n",
    "print(\"\\n Sample rows with misspellings:\")\n",
    "print(misspelled_rows[['comment', 'clean_comment', 'misspelled_words', 'misspelled_count']].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No emojis found in the dataset.\n"
     ]
    }
   ],
   "source": [
    "import emoji\n",
    "\n",
    "\n",
    "# Function to extract emojis from text\n",
    "def extract_emojis(text):\n",
    "    emoji_list = [char for char in text if emoji.is_emoji(char)]\n",
    "    return emoji_list\n",
    "\n",
    "# Apply on original 'comment' column\n",
    "train_df['emojis'] = train_df['comment'].apply(extract_emojis)\n",
    "\n",
    "# Count number of emojis\n",
    "train_df['emoji_count'] = train_df['emojis'].apply(len)\n",
    "\n",
    "# Filter rows with emojis\n",
    "emojified = train_df[train_df['emoji_count'] > 0]\n",
    "\n",
    "# Print results\n",
    "if emojified.empty:\n",
    "    print(\"No emojis found in the dataset.\")\n",
    "else:\n",
    "    print(\"Sample rows with emojis:\\n\")\n",
    "    print(emojified[['comment', 'emojis', 'emoji_count']].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 152296\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Just to count unique words\n",
    "cv = CountVectorizer()\n",
    "cv.fit(train_df['clean_comment'])\n",
    "\n",
    "vocab_size = len(cv.vocabulary_)\n",
    "print(f\"Vocabulary size: {vocab_size}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF matrix shape: (1010771, 20000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=20000)\n",
    "X_tfidf = vectorizer.fit_transform(train_df['clean_comment'])\n",
    "\n",
    "print(\"TF-IDF matrix shape:\", X_tfidf.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Train Shape: (808616, 20000)\n",
      "TF-IDF Test Shape: (202155, 20000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define TF-IDF Vectorizer\n",
    "tfidf = TfidfVectorizer(max_features=20000)\n",
    "\n",
    "# Split data into train/test (if not already done)\n",
    "X_train_text, X_test_text, y_train, y_test = train_test_split(\n",
    "    train_df['clean_comment'], \n",
    "    train_df['label'],     # replace 'label' with your target column name\n",
    "    test_size=0.2, \n",
    "    random_state=42,\n",
    "    stratify=train_df['label']\n",
    ")\n",
    "\n",
    "# Fit on training and transform both train and test\n",
    "X_train_tfidf = tfidf.fit_transform(X_train_text)\n",
    "X_test_tfidf = tfidf.transform(X_test_text)\n",
    "\n",
    "# Optional: Check dimensions\n",
    "print(f\"TF-IDF Train Shape: {X_train_tfidf.shape}\")\n",
    "print(f\"TF-IDF Test Shape: {X_test_tfidf.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Train Metrics:\n",
      "Loss: 0.5897 | Acc: 0.6848 | Prec: 0.6863 | Rec: 0.6848 | F1: 0.6841\n",
      "\n",
      "Average Test Metrics:\n",
      "Loss: 0.6010 | Acc: 0.6732 | Prec: 0.6748 | Rec: 0.6732 | F1: 0.6725\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# TF-IDF vectorization\n",
    "tfidf = TfidfVectorizer(max_features=20000)\n",
    "X = tfidf.fit_transform(train_df['clean_comment'])\n",
    "\n",
    "# Label column (change if yours is different)\n",
    "y = train_df['label']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Logistic Regression\n",
    "lr = LogisticRegression(max_iter=200)\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_train_pred = lr.predict(X_train)\n",
    "y_test_pred = lr.predict(X_test)\n",
    "\n",
    "# Probabilities (for log loss)\n",
    "y_train_prob = lr.predict_proba(X_train)\n",
    "y_test_prob = lr.predict_proba(X_test)\n",
    "\n",
    "# Average Train Metrics\n",
    "train_loss = log_loss(y_train, y_train_prob)\n",
    "train_acc = accuracy_score(y_train, y_train_pred)\n",
    "train_prec = precision_score(y_train, y_train_pred, average='weighted')\n",
    "train_rec = recall_score(y_train, y_train_pred, average='weighted')\n",
    "train_f1 = f1_score(y_train, y_train_pred, average='weighted')\n",
    "\n",
    "# Average Test Metrics\n",
    "test_loss = log_loss(y_test, y_test_prob)\n",
    "test_acc = accuracy_score(y_test, y_test_pred)\n",
    "test_prec = precision_score(y_test, y_test_pred, average='weighted')\n",
    "test_rec = recall_score(y_test, y_test_pred, average='weighted')\n",
    "test_f1 = f1_score(y_test, y_test_pred, average='weighted')\n",
    "\n",
    "# Final output format\n",
    "print(f\"Average Train Metrics:\\nLoss: {train_loss:.4f} | Acc: {train_acc:.4f} | Prec: {train_prec:.4f} | Rec: {train_rec:.4f} | F1: {train_f1:.4f}\")\n",
    "print(f\"\\nAverage Test Metrics:\\nLoss: {test_loss:.4f} | Acc: {test_acc:.4f} | Prec: {test_prec:.4f} | Rec: {test_rec:.4f} | F1: {test_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Train Metrics:\n",
      "Loss: 0.6843 | Acc: 0.5512 | Prec: 0.5498 | Rec: 0.5649 | F1: 0.5572\n",
      "\n",
      "Average Test Metrics:\n",
      "Loss: 0.6961 | Acc: 0.4979 | Prec: 0.4982 | Rec: 0.5129 | F1: 0.5054\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# Train SVM\n",
    "svm_clf = LinearSVC()\n",
    "svm_clf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predict\n",
    "y_train_pred = svm_clf.predict(X_train_tfidf)\n",
    "y_test_pred = svm_clf.predict(X_test_tfidf)\n",
    "\n",
    "# Probabilities (for log loss)\n",
    "# LinearSVC doesn't support predict_proba, so log loss can't be directly calculated.\n",
    "# Use decision_function instead and clip it to get pseudo-probabilities\n",
    "import numpy as np\n",
    "def safe_log_loss(y_true, y_scores):\n",
    "    probs = 1 / (1 + np.exp(-y_scores))  # Sigmoid\n",
    "    probs = np.vstack([1 - probs, probs]).T\n",
    "    return log_loss(y_true, probs)\n",
    "\n",
    "# Metrics\n",
    "def compute_metrics(y_true, y_pred, y_scores):\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    prec = precision_score(y_true, y_pred)\n",
    "    rec = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    loss = safe_log_loss(y_true, y_scores)\n",
    "    return loss, acc, prec, rec, f1\n",
    "\n",
    "train_loss, train_acc, train_prec, train_rec, train_f1 = compute_metrics(y_train, y_train_pred, svm_clf.decision_function(X_train_tfidf))\n",
    "test_loss, test_acc, test_prec, test_rec, test_f1 = compute_metrics(y_test, y_test_pred, svm_clf.decision_function(X_test_tfidf))\n",
    "\n",
    "# Display results\n",
    "print(f\"Average Train Metrics:\\nLoss: {train_loss:.4f} | Acc: {train_acc:.4f} | Prec: {train_prec:.4f} | Rec: {train_rec:.4f} | F1: {train_f1:.4f}\")\n",
    "print(f\"\\nAverage Test Metrics:\\nLoss: {test_loss:.4f} | Acc: {test_acc:.4f} | Prec: {test_prec:.4f} | Rec: {test_rec:.4f} | F1: {test_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Train Metrics:\n",
      "Loss: 0.6838 | Acc: 0.5504 | Prec: 0.5504 | Rec: 0.5504 | F1: 0.5503\n",
      "\n",
      "Average Test Metrics:\n",
      "Loss: 0.6967 | Acc: 0.4990 | Prec: 0.4990 | Rec: 0.4990 | F1: 0.4989\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "\n",
    "# Train the model\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predict\n",
    "y_train_pred = nb.predict(X_train_tfidf)\n",
    "y_test_pred = nb.predict(X_test_tfidf)\n",
    "\n",
    "# Probabilities for log loss\n",
    "y_train_proba = nb.predict_proba(X_train_tfidf)\n",
    "y_test_proba = nb.predict_proba(X_test_tfidf)\n",
    "\n",
    "# Calculate metrics\n",
    "train_loss = log_loss(y_train, y_train_proba)\n",
    "test_loss = log_loss(y_test, y_test_proba)\n",
    "\n",
    "train_acc = accuracy_score(y_train, y_train_pred)\n",
    "test_acc = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "train_prec = precision_score(y_train, y_train_pred, average='weighted')\n",
    "test_prec = precision_score(y_test, y_test_pred, average='weighted')\n",
    "\n",
    "train_rec = recall_score(y_train, y_train_pred, average='weighted')\n",
    "test_rec = recall_score(y_test, y_test_pred, average='weighted')\n",
    "\n",
    "train_f1 = f1_score(y_train, y_train_pred, average='weighted')\n",
    "test_f1 = f1_score(y_test, y_test_pred, average='weighted')\n",
    "\n",
    "# Print formatted results\n",
    "print(f\"\\nAverage Train Metrics:\\nLoss: {train_loss:.4f} | Acc: {train_acc:.4f} | Prec: {train_prec:.4f} | Rec: {train_rec:.4f} | F1: {train_f1:.4f}\")\n",
    "print(f\"\\nAverage Test Metrics:\\nLoss: {test_loss:.4f} | Acc: {test_acc:.4f} | Prec: {test_prec:.4f} | Rec: {test_rec:.4f} | F1: {test_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Train Metrics:\n",
      "Loss: 0.6927 | Acc: 0.5113 | Prec: 0.5440 | Rec: 0.5113 | F1: 0.3996\n",
      "\n",
      "Average Test Metrics:\n",
      "Loss: 0.6932 | Acc: 0.5001 | Prec: 0.5013 | Rec: 0.5001 | F1: 0.3854\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize RF with reasonable defaults (can tune later)\n",
    "rf = RandomForestClassifier(n_estimators=30, max_depth=20, random_state=42, n_jobs=-1)\n",
    "\n",
    "# Train\n",
    "rf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predict\n",
    "y_train_pred = rf.predict(X_train_tfidf)\n",
    "y_test_pred = rf.predict(X_test_tfidf)\n",
    "\n",
    "# Probabilities for log loss\n",
    "y_train_proba = rf.predict_proba(X_train_tfidf)\n",
    "y_test_proba = rf.predict_proba(X_test_tfidf)\n",
    "\n",
    "# Calculate metrics\n",
    "from sklearn.metrics import log_loss, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "train_loss = log_loss(y_train, y_train_proba)\n",
    "test_loss = log_loss(y_test, y_test_proba)\n",
    "\n",
    "train_acc = accuracy_score(y_train, y_train_pred)\n",
    "test_acc = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "train_prec = precision_score(y_train, y_train_pred, average='weighted')\n",
    "test_prec = precision_score(y_test, y_test_pred, average='weighted')\n",
    "\n",
    "train_rec = recall_score(y_train, y_train_pred, average='weighted')\n",
    "test_rec = recall_score(y_test, y_test_pred, average='weighted')\n",
    "\n",
    "train_f1 = f1_score(y_train, y_train_pred, average='weighted')\n",
    "test_f1 = f1_score(y_test, y_test_pred, average='weighted')\n",
    "\n",
    "# Display\n",
    "print(f\"\\nAverage Train Metrics:\\nLoss: {train_loss:.4f} | Acc: {train_acc:.4f} | Prec: {train_prec:.4f} | Rec: {train_rec:.4f} | F1: {train_f1:.4f}\")\n",
    "print(f\"\\nAverage Test Metrics:\\nLoss: {test_loss:.4f} | Acc: {test_acc:.4f} | Prec: {test_prec:.4f} | Rec: {test_rec:.4f} | F1: {test_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cvblgita/anaconda3/envs/nlp/lib/python3.9/site-packages/xgboost/core.py:265: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc 2.28+) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Train Metrics:\n",
      "Loss: 0.6900 | Acc: 0.5164 | Prec: 0.5867 | Rec: 0.1104 | F1: 0.1858\n",
      "\n",
      "Average Test Metrics:\n",
      "Loss: 0.6936 | Acc: 0.4999 | Prec: 0.5010 | Rec: 0.0931 | F1: 0.1571\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "# Initialize XGBoost model\n",
    "xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='logloss', verbosity=0, random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "xgb_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predict\n",
    "train_preds = xgb_model.predict(X_train_tfidf)\n",
    "test_preds = xgb_model.predict(X_test_tfidf)\n",
    "\n",
    "# Probabilities for log loss\n",
    "train_probs = xgb_model.predict_proba(X_train_tfidf)\n",
    "test_probs = xgb_model.predict_proba(X_test_tfidf)\n",
    "\n",
    "# Evaluation metrics\n",
    "def get_metrics(y_true, y_pred, y_prob):\n",
    "    loss = log_loss(y_true, y_prob)\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    prec = precision_score(y_true, y_pred)\n",
    "    rec = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    return loss, acc, prec, rec, f1\n",
    "\n",
    "train_loss, train_acc, train_prec, train_rec, train_f1 = get_metrics(y_train, train_preds, train_probs)\n",
    "test_loss, test_acc, test_prec, test_rec, test_f1 = get_metrics(y_test, test_preds, test_probs)\n",
    "\n",
    "# Print formatted output\n",
    "print(\"Average Train Metrics:\")\n",
    "print(f\"Loss: {train_loss:.4f} | Acc: {train_acc:.4f} | Prec: {train_prec:.4f} | Rec: {train_rec:.4f} | F1: {train_f1:.4f}\\n\")\n",
    "\n",
    "print(\"Average Test Metrics:\")\n",
    "print(f\"Loss: {test_loss:.4f} | Acc: {test_acc:.4f} | Prec: {test_prec:.4f} | Rec: {test_rec:.4f} | F1: {test_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "# Load Google News Word2Vec - 3 million words, 300 dimensions\n",
    "w2v_path = 'GoogleNews-vectors-negative300.bin.gz'\n",
    "word2vec = KeyedVectors.load_word2vec_format(w2v_path, binary=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch\n",
    "\n",
    "# 1. Tokenize the text\n",
    "def tokenize(text):\n",
    "    return text.split()\n",
    "\n",
    "tokenized_texts = [tokenize(text) for text in train_df['clean_comment']]\n",
    "\n",
    "# 2. Build vocabulary (limit to top 20,000)\n",
    "vocab = build_vocab_from_iterator(tokenized_texts, specials=[\"<pad>\", \"<unk>\"], max_tokens=20000)\n",
    "vocab.set_default_index(vocab[\"<unk>\"])  # For OOV tokens\n",
    "\n",
    "# 3. Convert tokens to indices\n",
    "indexed_texts = [torch.tensor(vocab(tokens)) for tokens in tokenized_texts]\n",
    "\n",
    "# 4. Pad sequences\n",
    "max_len = 100\n",
    "padded_seqs = pad_sequence(indexed_texts, batch_first=True, padding_value=vocab[\"<pad>\"])\n",
    "if padded_seqs.size(1) > max_len:\n",
    "    padded_seqs = padded_seqs[:, :max_len]\n",
    "else:\n",
    "    pad_width = max_len - padded_seqs.size(1)\n",
    "    padded_seqs = torch.nn.functional.pad(padded_seqs, (0, pad_width), value=vocab[\"<pad>\"])\n",
    "\n",
    "# 5. Labels\n",
    "labels = torch.tensor(train_df['label'].values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torchtext vocab object already built\n",
    "word_index = vocab.get_stoi()  # returns: {'the': 0, 'a': 1, ...}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "embedding_dim = 300\n",
    "num_words = min(20000, len(word_index))\n",
    "\n",
    "embedding_matrix = np.zeros((num_words, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    if i >= 20000:\n",
    "        continue\n",
    "    if word in word2vec:\n",
    "        embedding_matrix[i] = word2vec[word]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# already created padded_seqs and labels in previous step\n",
    "# make sure they are torch tensors\n",
    "X_tensor = padded_seqs.long()\n",
    "y_tensor = labels.long()\n",
    "\n",
    "# Dataset and DataLoader\n",
    "dataset = TensorDataset(X_tensor, y_tensor)\n",
    "train_loader = DataLoader(dataset, batch_size=64, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('padded_sequences.pkl', 'wb') as f:\n",
    "    pickle.dump(padded_seqs, f)\n",
    "\n",
    "with open('labels.npy', 'wb') as f:\n",
    "    np.save(f, labels)\n",
    "\n",
    "with open('embedding_matrix.npy', 'wb') as f:\n",
    "    np.save(f, embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('word_index.pkl', 'wb') as f:\n",
    "    pickle.dump(word_index, f)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
